{
 "metadata": {
  "name": "",
  "signature": "sha256:6a0229fed4a52f7e9e09e3a346b0bfaa27edc912bb0cf8f8646a37211b56bcde"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Homework 2**\n",
      "Question 1. Implement KNN classification, using the sklearn package. We learned how to do this in class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = pd.DataFrame.from_csv('data/iris_data.csv',index_col=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sepal_length</th>\n",
        "      <th>Sepal_width</th>\n",
        "      <th>Petal_length</th>\n",
        "      <th>Petal_width</th>\n",
        "      <th>Class</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   Sepal_length  Sepal_width  Petal_length  Petal_width        Class\n",
        "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
        "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
        "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
        "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
        "4           5.0          3.6           1.4          0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "iris.tail()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sepal_length</th>\n",
        "      <th>Sepal_width</th>\n",
        "      <th>Petal_length</th>\n",
        "      <th>Petal_width</th>\n",
        "      <th>Class</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>145</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.2</td>\n",
        "      <td> 2.3</td>\n",
        "      <td> Iris-virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>146</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 2.5</td>\n",
        "      <td> 5.0</td>\n",
        "      <td> 1.9</td>\n",
        "      <td> Iris-virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>147</th>\n",
        "      <td> 6.5</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.2</td>\n",
        "      <td> 2.0</td>\n",
        "      <td> Iris-virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>148</th>\n",
        "      <td> 6.2</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 5.4</td>\n",
        "      <td> 2.3</td>\n",
        "      <td> Iris-virginica</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149</th>\n",
        "      <td> 5.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.1</td>\n",
        "      <td> 1.8</td>\n",
        "      <td> Iris-virginica</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "     Sepal_length  Sepal_width  Petal_length  Petal_width           Class\n",
        "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
        "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
        "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
        "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
        "149           5.9          3.0           5.1          1.8  Iris-virginica"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = iris['Class'].copy()\n",
      "hash={'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica' : 2 }\n",
      "names = np.array(['Iris-setosa','Iris-versicolor', 'Iris-virginica' ])\n",
      "                             "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0     Iris-setosa\n",
        "1     Iris-setosa\n",
        "2     Iris-setosa\n",
        "3     Iris-setosa\n",
        "4     Iris-setosa\n",
        "5     Iris-setosa\n",
        "6     Iris-setosa\n",
        "7     Iris-setosa\n",
        "8     Iris-setosa\n",
        "9     Iris-setosa\n",
        "10    Iris-setosa\n",
        "11    Iris-setosa\n",
        "12    Iris-setosa\n",
        "13    Iris-setosa\n",
        "14    Iris-setosa\n",
        "...\n",
        "135    Iris-virginica\n",
        "136    Iris-virginica\n",
        "137    Iris-virginica\n",
        "138    Iris-virginica\n",
        "139    Iris-virginica\n",
        "140    Iris-virginica\n",
        "141    Iris-virginica\n",
        "142    Iris-virginica\n",
        "143    Iris-virginica\n",
        "144    Iris-virginica\n",
        "145    Iris-virginica\n",
        "146    Iris-virginica\n",
        "147    Iris-virginica\n",
        "148    Iris-virginica\n",
        "149    Iris-virginica\n",
        "Name: Class, Length: 150, dtype: object"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sepal_length</th>\n",
        "      <th>Sepal_width</th>\n",
        "      <th>Petal_length</th>\n",
        "      <th>Petal_width</th>\n",
        "      <th>Class</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> Iris-setosa</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "   Sepal_length  Sepal_width  Petal_length  Petal_width        Class\n",
        "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
        "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
        "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
        "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
        "4           5.0          3.6           1.4          0.2  Iris-setosa"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(target)):\n",
      "    target[i] = hash[target[i]]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0     0\n",
        "1     0\n",
        "2     0\n",
        "3     0\n",
        "4     0\n",
        "5     0\n",
        "6     0\n",
        "7     0\n",
        "8     0\n",
        "9     0\n",
        "10    0\n",
        "11    0\n",
        "12    0\n",
        "13    0\n",
        "14    0\n",
        "...\n",
        "135    2\n",
        "136    2\n",
        "137    2\n",
        "138    2\n",
        "139    2\n",
        "140    2\n",
        "141    2\n",
        "142    2\n",
        "143    2\n",
        "144    2\n",
        "145    2\n",
        "146    2\n",
        "147    2\n",
        "148    2\n",
        "149    2\n",
        "Name: Class, Length: 150, dtype: object"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "data= iris[['Sepal_length','Sepal_width','Petal_length','Petal_width']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sepal_length</th>\n",
        "      <th>Sepal_width</th>\n",
        "      <th>Petal_length</th>\n",
        "      <th>Petal_width</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1  </th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2  </th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3  </th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4  </th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5  </th>\n",
        "      <td> 5.4</td>\n",
        "      <td> 3.9</td>\n",
        "      <td> 1.7</td>\n",
        "      <td> 0.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6  </th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7  </th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8  </th>\n",
        "      <td> 4.4</td>\n",
        "      <td> 2.9</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9  </th>\n",
        "      <td> 4.9</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10 </th>\n",
        "      <td> 5.4</td>\n",
        "      <td> 3.7</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11 </th>\n",
        "      <td> 4.8</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.6</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12 </th>\n",
        "      <td> 4.8</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13 </th>\n",
        "      <td> 4.3</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.1</td>\n",
        "      <td> 0.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14 </th>\n",
        "      <td> 5.8</td>\n",
        "      <td> 4.0</td>\n",
        "      <td> 1.2</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15 </th>\n",
        "      <td> 5.7</td>\n",
        "      <td> 4.4</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16 </th>\n",
        "      <td> 5.4</td>\n",
        "      <td> 3.9</td>\n",
        "      <td> 1.3</td>\n",
        "      <td> 0.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17 </th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18 </th>\n",
        "      <td> 5.7</td>\n",
        "      <td> 3.8</td>\n",
        "      <td> 1.7</td>\n",
        "      <td> 0.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19 </th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.8</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20 </th>\n",
        "      <td> 5.4</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.7</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21 </th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.7</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22 </th>\n",
        "      <td> 4.6</td>\n",
        "      <td> 3.6</td>\n",
        "      <td> 1.0</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23 </th>\n",
        "      <td> 5.1</td>\n",
        "      <td> 3.3</td>\n",
        "      <td> 1.7</td>\n",
        "      <td> 0.5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24 </th>\n",
        "      <td> 4.8</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.9</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25 </th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 1.6</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26 </th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.6</td>\n",
        "      <td> 0.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27 </th>\n",
        "      <td> 5.2</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 1.5</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28 </th>\n",
        "      <td> 5.2</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 1.4</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29 </th>\n",
        "      <td> 4.7</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 1.6</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>120</th>\n",
        "      <td> 6.9</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 5.7</td>\n",
        "      <td> 2.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>121</th>\n",
        "      <td> 5.6</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 4.9</td>\n",
        "      <td> 2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>122</th>\n",
        "      <td> 7.7</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 6.7</td>\n",
        "      <td> 2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>123</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 2.7</td>\n",
        "      <td> 4.9</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>124</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.3</td>\n",
        "      <td> 5.7</td>\n",
        "      <td> 2.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>125</th>\n",
        "      <td> 7.2</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 6.0</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>126</th>\n",
        "      <td> 6.2</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 4.8</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>127</th>\n",
        "      <td> 6.1</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 4.9</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>128</th>\n",
        "      <td> 6.4</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> 2.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>129</th>\n",
        "      <td> 7.2</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.8</td>\n",
        "      <td> 1.6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>130</th>\n",
        "      <td> 7.4</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 6.1</td>\n",
        "      <td> 1.9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>131</th>\n",
        "      <td> 7.9</td>\n",
        "      <td> 3.8</td>\n",
        "      <td> 6.4</td>\n",
        "      <td> 2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>132</th>\n",
        "      <td> 6.4</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> 2.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>133</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> 5.1</td>\n",
        "      <td> 1.5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>134</th>\n",
        "      <td> 6.1</td>\n",
        "      <td> 2.6</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> 1.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>135</th>\n",
        "      <td> 7.7</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 6.1</td>\n",
        "      <td> 2.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>136</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> 2.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>137</th>\n",
        "      <td> 6.4</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 5.5</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>138</th>\n",
        "      <td> 6.0</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 4.8</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>139</th>\n",
        "      <td> 6.9</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 5.4</td>\n",
        "      <td> 2.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>140</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> 2.4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>141</th>\n",
        "      <td> 6.9</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> 5.1</td>\n",
        "      <td> 2.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>142</th>\n",
        "      <td> 5.8</td>\n",
        "      <td> 2.7</td>\n",
        "      <td> 5.1</td>\n",
        "      <td> 1.9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>143</th>\n",
        "      <td> 6.8</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> 5.9</td>\n",
        "      <td> 2.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>144</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.3</td>\n",
        "      <td> 5.7</td>\n",
        "      <td> 2.5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>145</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.2</td>\n",
        "      <td> 2.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>146</th>\n",
        "      <td> 6.3</td>\n",
        "      <td> 2.5</td>\n",
        "      <td> 5.0</td>\n",
        "      <td> 1.9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>147</th>\n",
        "      <td> 6.5</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.2</td>\n",
        "      <td> 2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>148</th>\n",
        "      <td> 6.2</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> 5.4</td>\n",
        "      <td> 2.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149</th>\n",
        "      <td> 5.9</td>\n",
        "      <td> 3.0</td>\n",
        "      <td> 5.1</td>\n",
        "      <td> 1.8</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>150 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "     Sepal_length  Sepal_width  Petal_length  Petal_width\n",
        "0             5.1          3.5           1.4          0.2\n",
        "1             4.9          3.0           1.4          0.2\n",
        "2             4.7          3.2           1.3          0.2\n",
        "3             4.6          3.1           1.5          0.2\n",
        "4             5.0          3.6           1.4          0.2\n",
        "5             5.4          3.9           1.7          0.4\n",
        "6             4.6          3.4           1.4          0.3\n",
        "7             5.0          3.4           1.5          0.2\n",
        "8             4.4          2.9           1.4          0.2\n",
        "9             4.9          3.1           1.5          0.1\n",
        "10            5.4          3.7           1.5          0.2\n",
        "11            4.8          3.4           1.6          0.2\n",
        "12            4.8          3.0           1.4          0.1\n",
        "13            4.3          3.0           1.1          0.1\n",
        "14            5.8          4.0           1.2          0.2\n",
        "15            5.7          4.4           1.5          0.4\n",
        "16            5.4          3.9           1.3          0.4\n",
        "17            5.1          3.5           1.4          0.3\n",
        "18            5.7          3.8           1.7          0.3\n",
        "19            5.1          3.8           1.5          0.3\n",
        "20            5.4          3.4           1.7          0.2\n",
        "21            5.1          3.7           1.5          0.4\n",
        "22            4.6          3.6           1.0          0.2\n",
        "23            5.1          3.3           1.7          0.5\n",
        "24            4.8          3.4           1.9          0.2\n",
        "25            5.0          3.0           1.6          0.2\n",
        "26            5.0          3.4           1.6          0.4\n",
        "27            5.2          3.5           1.5          0.2\n",
        "28            5.2          3.4           1.4          0.2\n",
        "29            4.7          3.2           1.6          0.2\n",
        "..            ...          ...           ...          ...\n",
        "120           6.9          3.2           5.7          2.3\n",
        "121           5.6          2.8           4.9          2.0\n",
        "122           7.7          2.8           6.7          2.0\n",
        "123           6.3          2.7           4.9          1.8\n",
        "124           6.7          3.3           5.7          2.1\n",
        "125           7.2          3.2           6.0          1.8\n",
        "126           6.2          2.8           4.8          1.8\n",
        "127           6.1          3.0           4.9          1.8\n",
        "128           6.4          2.8           5.6          2.1\n",
        "129           7.2          3.0           5.8          1.6\n",
        "130           7.4          2.8           6.1          1.9\n",
        "131           7.9          3.8           6.4          2.0\n",
        "132           6.4          2.8           5.6          2.2\n",
        "133           6.3          2.8           5.1          1.5\n",
        "134           6.1          2.6           5.6          1.4\n",
        "135           7.7          3.0           6.1          2.3\n",
        "136           6.3          3.4           5.6          2.4\n",
        "137           6.4          3.1           5.5          1.8\n",
        "138           6.0          3.0           4.8          1.8\n",
        "139           6.9          3.1           5.4          2.1\n",
        "140           6.7          3.1           5.6          2.4\n",
        "141           6.9          3.1           5.1          2.3\n",
        "142           5.8          2.7           5.1          1.9\n",
        "143           6.8          3.2           5.9          2.3\n",
        "144           6.7          3.3           5.7          2.5\n",
        "145           6.7          3.0           5.2          2.3\n",
        "146           6.3          2.5           5.0          1.9\n",
        "147           6.5          3.0           5.2          2.0\n",
        "148           6.2          3.4           5.4          2.3\n",
        "149           5.9          3.0           5.1          1.8\n",
        "\n",
        "[150 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[ 5.1,  3.5,  1.4,  0.2],\n",
        "       [ 4.9,  3. ,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.3,  0.2],\n",
        "       [ 4.6,  3.1,  1.5,  0.2],\n",
        "       [ 5. ,  3.6,  1.4,  0.2],\n",
        "       [ 5.4,  3.9,  1.7,  0.4],\n",
        "       [ 4.6,  3.4,  1.4,  0.3],\n",
        "       [ 5. ,  3.4,  1.5,  0.2],\n",
        "       [ 4.4,  2.9,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5.4,  3.7,  1.5,  0.2],\n",
        "       [ 4.8,  3.4,  1.6,  0.2],\n",
        "       [ 4.8,  3. ,  1.4,  0.1],\n",
        "       [ 4.3,  3. ,  1.1,  0.1],\n",
        "       [ 5.8,  4. ,  1.2,  0.2],\n",
        "       [ 5.7,  4.4,  1.5,  0.4],\n",
        "       [ 5.4,  3.9,  1.3,  0.4],\n",
        "       [ 5.1,  3.5,  1.4,  0.3],\n",
        "       [ 5.7,  3.8,  1.7,  0.3],\n",
        "       [ 5.1,  3.8,  1.5,  0.3],\n",
        "       [ 5.4,  3.4,  1.7,  0.2],\n",
        "       [ 5.1,  3.7,  1.5,  0.4],\n",
        "       [ 4.6,  3.6,  1. ,  0.2],\n",
        "       [ 5.1,  3.3,  1.7,  0.5],\n",
        "       [ 4.8,  3.4,  1.9,  0.2],\n",
        "       [ 5. ,  3. ,  1.6,  0.2],\n",
        "       [ 5. ,  3.4,  1.6,  0.4],\n",
        "       [ 5.2,  3.5,  1.5,  0.2],\n",
        "       [ 5.2,  3.4,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.6,  0.2],\n",
        "       [ 4.8,  3.1,  1.6,  0.2],\n",
        "       [ 5.4,  3.4,  1.5,  0.4],\n",
        "       [ 5.2,  4.1,  1.5,  0.1],\n",
        "       [ 5.5,  4.2,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5. ,  3.2,  1.2,  0.2],\n",
        "       [ 5.5,  3.5,  1.3,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 4.4,  3. ,  1.3,  0.2],\n",
        "       [ 5.1,  3.4,  1.5,  0.2],\n",
        "       [ 5. ,  3.5,  1.3,  0.3],\n",
        "       [ 4.5,  2.3,  1.3,  0.3],\n",
        "       [ 4.4,  3.2,  1.3,  0.2],\n",
        "       [ 5. ,  3.5,  1.6,  0.6],\n",
        "       [ 5.1,  3.8,  1.9,  0.4],\n",
        "       [ 4.8,  3. ,  1.4,  0.3],\n",
        "       [ 5.1,  3.8,  1.6,  0.2],\n",
        "       [ 4.6,  3.2,  1.4,  0.2],\n",
        "       [ 5.3,  3.7,  1.5,  0.2],\n",
        "       [ 5. ,  3.3,  1.4,  0.2],\n",
        "       [ 7. ,  3.2,  4.7,  1.4],\n",
        "       [ 6.4,  3.2,  4.5,  1.5],\n",
        "       [ 6.9,  3.1,  4.9,  1.5],\n",
        "       [ 5.5,  2.3,  4. ,  1.3],\n",
        "       [ 6.5,  2.8,  4.6,  1.5],\n",
        "       [ 5.7,  2.8,  4.5,  1.3],\n",
        "       [ 6.3,  3.3,  4.7,  1.6],\n",
        "       [ 4.9,  2.4,  3.3,  1. ],\n",
        "       [ 6.6,  2.9,  4.6,  1.3],\n",
        "       [ 5.2,  2.7,  3.9,  1.4],\n",
        "       [ 5. ,  2. ,  3.5,  1. ],\n",
        "       [ 5.9,  3. ,  4.2,  1.5],\n",
        "       [ 6. ,  2.2,  4. ,  1. ],\n",
        "       [ 6.1,  2.9,  4.7,  1.4],\n",
        "       [ 5.6,  2.9,  3.6,  1.3],\n",
        "       [ 6.7,  3.1,  4.4,  1.4],\n",
        "       [ 5.6,  3. ,  4.5,  1.5],\n",
        "       [ 5.8,  2.7,  4.1,  1. ],\n",
        "       [ 6.2,  2.2,  4.5,  1.5],\n",
        "       [ 5.6,  2.5,  3.9,  1.1],\n",
        "       [ 5.9,  3.2,  4.8,  1.8],\n",
        "       [ 6.1,  2.8,  4. ,  1.3],\n",
        "       [ 6.3,  2.5,  4.9,  1.5],\n",
        "       [ 6.1,  2.8,  4.7,  1.2],\n",
        "       [ 6.4,  2.9,  4.3,  1.3],\n",
        "       [ 6.6,  3. ,  4.4,  1.4],\n",
        "       [ 6.8,  2.8,  4.8,  1.4],\n",
        "       [ 6.7,  3. ,  5. ,  1.7],\n",
        "       [ 6. ,  2.9,  4.5,  1.5],\n",
        "       [ 5.7,  2.6,  3.5,  1. ],\n",
        "       [ 5.5,  2.4,  3.8,  1.1],\n",
        "       [ 5.5,  2.4,  3.7,  1. ],\n",
        "       [ 5.8,  2.7,  3.9,  1.2],\n",
        "       [ 6. ,  2.7,  5.1,  1.6],\n",
        "       [ 5.4,  3. ,  4.5,  1.5],\n",
        "       [ 6. ,  3.4,  4.5,  1.6],\n",
        "       [ 6.7,  3.1,  4.7,  1.5],\n",
        "       [ 6.3,  2.3,  4.4,  1.3],\n",
        "       [ 5.6,  3. ,  4.1,  1.3],\n",
        "       [ 5.5,  2.5,  4. ,  1.3],\n",
        "       [ 5.5,  2.6,  4.4,  1.2],\n",
        "       [ 6.1,  3. ,  4.6,  1.4],\n",
        "       [ 5.8,  2.6,  4. ,  1.2],\n",
        "       [ 5. ,  2.3,  3.3,  1. ],\n",
        "       [ 5.6,  2.7,  4.2,  1.3],\n",
        "       [ 5.7,  3. ,  4.2,  1.2],\n",
        "       [ 5.7,  2.9,  4.2,  1.3],\n",
        "       [ 6.2,  2.9,  4.3,  1.3],\n",
        "       [ 5.1,  2.5,  3. ,  1.1],\n",
        "       [ 5.7,  2.8,  4.1,  1.3],\n",
        "       [ 6.3,  3.3,  6. ,  2.5],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 7.1,  3. ,  5.9,  2.1],\n",
        "       [ 6.3,  2.9,  5.6,  1.8],\n",
        "       [ 6.5,  3. ,  5.8,  2.2],\n",
        "       [ 7.6,  3. ,  6.6,  2.1],\n",
        "       [ 4.9,  2.5,  4.5,  1.7],\n",
        "       [ 7.3,  2.9,  6.3,  1.8],\n",
        "       [ 6.7,  2.5,  5.8,  1.8],\n",
        "       [ 7.2,  3.6,  6.1,  2.5],\n",
        "       [ 6.5,  3.2,  5.1,  2. ],\n",
        "       [ 6.4,  2.7,  5.3,  1.9],\n",
        "       [ 6.8,  3. ,  5.5,  2.1],\n",
        "       [ 5.7,  2.5,  5. ,  2. ],\n",
        "       [ 5.8,  2.8,  5.1,  2.4],\n",
        "       [ 6.4,  3.2,  5.3,  2.3],\n",
        "       [ 6.5,  3. ,  5.5,  1.8],\n",
        "       [ 7.7,  3.8,  6.7,  2.2],\n",
        "       [ 7.7,  2.6,  6.9,  2.3],\n",
        "       [ 6. ,  2.2,  5. ,  1.5],\n",
        "       [ 6.9,  3.2,  5.7,  2.3],\n",
        "       [ 5.6,  2.8,  4.9,  2. ],\n",
        "       [ 7.7,  2.8,  6.7,  2. ],\n",
        "       [ 6.3,  2.7,  4.9,  1.8],\n",
        "       [ 6.7,  3.3,  5.7,  2.1],\n",
        "       [ 7.2,  3.2,  6. ,  1.8],\n",
        "       [ 6.2,  2.8,  4.8,  1.8],\n",
        "       [ 6.1,  3. ,  4.9,  1.8],\n",
        "       [ 6.4,  2.8,  5.6,  2.1],\n",
        "       [ 7.2,  3. ,  5.8,  1.6],\n",
        "       [ 7.4,  2.8,  6.1,  1.9],\n",
        "       [ 7.9,  3.8,  6.4,  2. ],\n",
        "       [ 6.4,  2.8,  5.6,  2.2],\n",
        "       [ 6.3,  2.8,  5.1,  1.5],\n",
        "       [ 6.1,  2.6,  5.6,  1.4],\n",
        "       [ 7.7,  3. ,  6.1,  2.3],\n",
        "       [ 6.3,  3.4,  5.6,  2.4],\n",
        "       [ 6.4,  3.1,  5.5,  1.8],\n",
        "       [ 6. ,  3. ,  4.8,  1.8],\n",
        "       [ 6.9,  3.1,  5.4,  2.1],\n",
        "       [ 6.7,  3.1,  5.6,  2.4],\n",
        "       [ 6.9,  3.1,  5.1,  2.3],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 6.8,  3.2,  5.9,  2.3],\n",
        "       [ 6.7,  3.3,  5.7,  2.5],\n",
        "       [ 6.7,  3. ,  5.2,  2.3],\n",
        "       [ 6.3,  2.5,  5. ,  1.9],\n",
        "       [ 6.5,  3. ,  5.2,  2. ],\n",
        "       [ 6.2,  3.4,  5.4,  2.3],\n",
        "       [ 5.9,  3. ,  5.1,  1.8]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(target[0]) is int\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = target.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = y.astype(np.int64)\n",
      "y.dtype\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn = KNeighborsClassifier(3).fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 2**- Implement cross-validation for your KNN classifier. You may find it helpful to start with the cross-validation code from the lab. Note that you may need to re- write portions of that code to get it to work for you. Use 5 folds for your cross- validation. Do NOT use the cross_val_score method from sklearn to do this \u201cblack box\u201d for you."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_validate(X,y,classifier, k_fold):\n",
      "    k_fold_indices = KFold(len(X), n_folds=k_fold, indices=True, shuffle=True, random_state=0)\n",
      "    k_score_total = 0\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "        model = classifier(X[[train_slice]], y[[train_slice]])\n",
      "        k_score = model.score(X[[test_slice]], y[[test_slice]])\n",
      "        k_score_total += k_score\n",
      "    return k_score_total/k_fold "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y,KNeighborsClassifier(3).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.95333333333333337"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\ufffc\ufffc\n",
      "**Question 3**. Use your KNN classifier and cross-validation code from (1) and (2) above to determine the optimal value of K (number of nearest neighbors to consult) for this Iris dataset. This hyperparameter will be a number between 1 and 150J\uf04a.\n",
      "\n",
      "11 seems to be the best value for K (and also 15)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#when i use KNeighborsClassifier(k), the argument is the number of nearest neigbors. So I want to write a method that identify the highest k\n",
      "\n",
      "def highest_k():\n",
      "   k = 1 \n",
      "   max_k = 1\n",
      "   max_score = cross_validate(X,y, KNeighborsClassifier(1).fit, 5)\n",
      "   while (k<150):\n",
      "        k += 1\n",
      "        score = cross_validate(X,y, KNeighborsClassifier(k).fit, 5)\n",
      "        if score > max_score :\n",
      "            max_score = score\n",
      "            max_k = k\n",
      "   return max_k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "highest_k()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "11"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y, KNeighborsClassifier(2).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.94000000000000006"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y, KNeighborsClassifier(3).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "0.95333333333333337"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y, KNeighborsClassifier(5).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "0.95999999999999996"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y, KNeighborsClassifier(15).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "0.96666666666666656"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y, KNeighborsClassifier(150).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0.23999999999999999"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X,y, KNeighborsClassifier(11).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "0.96666666666666656"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 4 -Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range of K that you consider interesting. Explain in words what you are seeing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def validation(k):\n",
      "    return cross_validate(X,y, KNeighborsClassifier(k).fit, 5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.96666666666666656"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "x_par = np.arange(1,150)\n",
      "y_par = [validation(param) for param in x_par]\n",
      "%pylab inline\n",
      "plt.plot(x_par, y_par)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[<matplotlib.lines.Line2D at 0x108e701d0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108bbbb10>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = np.arange(1, 25)\n",
      "y_s = [validation(x) for x in s]\n",
      "%pylab inline\n",
      "plt.plot(s, y_s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "[<matplotlib.lines.Line2D at 0x108fcabd0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2QVPWd7/F3MzzJgAMIDAgIxEdQRFBHEJThYYjuZqOx\naq9xa0s3Ji6burquqbura1VuMLd2F3M3ca0iN+teH+Le7F29SdaspjQyPAyIIoqMPKigzABheI4o\n8vww0/eP7+nMoemZc073Od3ndH9eVV30ef7Rc/p8+/cMIiIiIiIiIiIiIiIiIiIiIiIiIiIiZ7kF\n2Ax8AjycY/sg4CVgPbAGuNJZfznQ7HodAv7S2TYYaAQ+BhYDAyNKu4iIFKgK2AqMBXoB7wPjs/b5\nn8B3nfeXA0tynKcHsAcY7Sz/APgb5/3DwMLQUiwiIqGaBvzGtfyI83L7NTDDtbwVGJq1zzxglWt5\nM1DrvB/uLIuISAn08Ng+EtjpWm5z1rmtB+5w3tcBY4BRWft8Hfi/ruVaYJ/zfh+dQUFERIrMKxCk\nfZxjIVbG3wzc7/zb7treG/gj4OfdXMPPdUREJAI9PbbvorNcH+d9W9Y+h4F7XcvbgFbX8q3Ae8AB\n17p9WJHQXmAEsD/XxS+++OJ0S0uLRxJFRMSlBbgkyAFeOYK1wKVYZXFv4E7g5ax9apxtAPcBK4Aj\nru13Af+edczLwD3O+3uAX+W6eEtLC+l0Wq90mu9973slT0McXvoc9Fnos+j+BVzs8Vw/h1eO4AxW\n3PM61oLoGeAjYL6z/SlgAvBTrHhnE/BN1/HVwFwsQLgtBP6fs+924L8ETbiIiITDKxAAvOa83J5y\nvV+NNRvN5SgwJMf6g1iAEBGREvMqGpKYqK+vL3USYkGfQyd9Fp30WRQmVeoEeEg7ZV4iIuJDKpWC\ngM925QhERCqcAoGISIVTIBARqXAKBCIiFU6BQESkwikQiIhUOAUCEZEKp0AgIlLhFAhERCqcAoGI\nSIVTIBARqXAKBCIiFU6BQESkwikQiIhUOAUCEZEKp0AgIlLhFAhERCqcAoGUvdOnoaOj1KkI36lT\npU6BlAsFAil73/gG/PM/lzoV4Tp0CMaMAc3kKmFQIJCy1t4Or70Gr75a6pSEa+tW2LsXDh8udUqk\nHCgQSFlrbobqanjjjfIqSmlpsX/37SttOqQ8KBBIWWtshK99DS69FN5+u9SpCU9rq/2rQCBhUCCQ\nstbYCA0N9mpsLHVqwqMcgYRJgUDK1rFj8O67MHNm+QWC1lb40pesnkCkUAoEUrZWroTJk2HAAJg+\nHT74AD77rNSpCkdLC9x4o3IEEg4FAilbixdbTgCgTx8LBsuWlTZNYTh1CvbsgeuvVyCQcPgJBLcA\nm4FPgIdzbB8EvASsB9YAV7q2DQR+AXwEfAjc4KxfALQBzc7rluBJF+lepn4go1yKh3bsgJEjYdQo\nBQIJh1cgqAIWYQ/qCcBdwPisfR4F1gGTgLuBJ13bngRedY65GgsoAGngR8Bk5/WbvP8HIjns2QO7\ndsF113WumzevPAJBSwtcfDHU1ioQSDi8AkEdsBXYDpwGXgBuy9pnPLDceb8FGAsMBWqAm4BnnW1n\ngEOu41J5plnE05IlMGsW9OzZue6qq6wCOdP0MqlaWxUIJFxegWAksNO13Oasc1sP3OG8rwPGAKOA\nccAB4Dksx/C/gX6u4x5wjn0GK0ISCU12sRBAKgVz5yY/V9DSYi2GFAgkLF6BwM9IJguxB3kzcL/z\nbzvQE5gC/C/n36PAI84xP8ECxTXAHuCHQRMu0pV02nIE2YEAyqOeIJMj6N/f/q9HjpQ6RZJ0PT22\n7wJGu5ZHY7kCt8PAva7lbUAr0N/Z911n/S/oDAT7Xfs/DbzSVQIWLFjw+/f19fXU19d7JFkq3Qcf\nQN++9rDMNncu/NVf2RhEVVXFT1sYMjmCVKozV9C/f6lTJaXS1NREU1NTQefwKqfviZX7zwF2A+9g\nFcYfufapAY4Dp4D7gOnAnznbVgLfAj7GWgqdh7U8GoHlBAAeAq4H/iTH9dNpDa8oAT3xBGzeDE89\nlXv7VVfBs89CXV1x0xWGdNr6RezaBTU1MHUq/OhH1qdABCCVSkHAOlivHMEZrLjndawF0TNYEJjv\nbH8Ka030U6wYaRPwTdfxDwD/BvQGWoBvOOsfx4qF0lgOYj4iIWlshHvv7Xp7pngoiYFg/37L7dTU\n2LLqCSQMcW+5oxyBBHLyJAwZYm3tBw/Ovc+rr8Ljj8OKFcVNWxjeegseegjWrLHlP/9zmDIF/uIv\nSpsuiY98cgTqWSxl5a23YMKEroMA2NhD772XzErWTEVxhnIEEgYFAikruZqNZquutuEZkpgjyFQU\nZygQSBgUCKSs+AkEkNxmpMoRSBQUCKRsfPopbNkC06Z575vUQKAcgURBgUDKxrJlcNNN0Lu3975T\npthY/rt2RZ+uMClHIFFQIJCy4bdYCKwz2ezZ1gM5KY4ds/kULrywc50CgYRBgUDKQjodLBBA8oqH\nWlth7Fjo4frW1tTY/ATHj5csWVIGFAikLLS02ANxwgT/xzQ0WI4gKV1VMtNTuqVSMGyYcgVSGAUC\nKQuZ3EAqQDeaceNsuIaNG6NLV5gy8xBkU/GQFEqBQMqCe1rKIBoa7NgkyK4ozlAgkEIpEEjinTkD\nTU02smhQSaonyG46mqFAIIVSIJDEe/dduOgieyAGNWuWDUtx4kT46QqbcgQSFQUCSbygrYXcBg60\nYanffDPcNIWtvR22b7d6jWy1tdYnQiRfCgSSeIUEAkhG8dCuXXDBBXDeeeduU45ACqVAIIl2+DC8\n/771KM5XEgJBrqajGQoEUigFAkm0piabYKZfv/zPMXUqbN0Kv/tdaMkKXVdNR0GBQAqnQCCJ1tgI\n8+YVdo5evWyOgqVLw0lTFJQjkCgpEEiiFVo/kBH34qHucgSDBtk4RElo+STxpEAgibVzpxXnXHNN\n4efKBIK4DjfRVdNRsLGHhg2z+YxF8qFAIInV2Ahz5pw9CFu+Lr8cOjrg448LP1cUuupMlqHiISmE\nAoEkVljFQmBjFMW1eOjzz21AvaFDu95HgUAKoUAgidTRYZW7YQUCiG8gyFQUdzegngKBFEKBQBJp\n/XqrJL3oovDOOWeOTWh/+nR45wxDdxXFGQoEUggFAkmkMIuFMoYNsyEc3nkn3PMWqrumoxkKBFII\nBQJJpDD6D+Qyb178ioeUI5CoKRBI4hw/Dm+/DfX14Z87jvUE3TUdzVAgkEIoEEjirFoFkybB+eeH\nf+4ZM2DDBjh0KPxz58ur6SgoEEhhFAgkcaKoH8jo2xemTbMxjOLg9GnYvRvGjOl+PwUCKYQCgSRO\nvtNS+hWn6St37IALL7TxkLpzwQXwxRfxa/EkyeAnENwCbAY+AR7OsX0Q8BKwHlgDXOnaNhD4BfAR\n8CEw1Vk/GGgEPgYWO/uJeNq3zyZoqauL7hpxqifwU1EM1rt6yBANMyH58QoEVcAiLBhMAO4Cxmft\n8yiwDpgE3A086dr2JPCqc8zVWEAAeAQLBJcBS51lEU9Ll1olcc+e0V3j6qutN++OHdFdwy8/TUcz\nVDwk+fIKBHXAVmA7cBp4Abgta5/xwHLn/RZgLDAUqAFuAp51tp0BMlVwXwWed94/D9yeT+Kl8kRZ\nP5DRowfMnRuPXIHfHAEoEEj+vH5XjQR2upbbgBuy9lkP3AGswgLHGGAUkAYOAM9huYX3gAeBY0At\nkLll9znLBWtstKn8ZswI42zh27EDnnsu+HEDBsBDD4UzuFoUfv5z+OCD4lzr1Vfh0Uejv868ebBo\nEbS1BTuuZ0/7W1VXh5OO1la4Ifsb1wUFAsmXVyDwMyjvQqwIqBnY6PzbDvQGpgD3A+8C/4QVAf33\nHNfo8joLFiz4/fv6+nrqu2k8vnq1Dc4V10Dw9NPW/n369GDHPfGEDX8QxnDLYTtzBubPh29/27tC\nMwyPPgqXXBL9dW6/3Ya5bm8PdtyLL8KECXDHHeGkQzkC8dLU1ERTgc3cvALBLmC0a3k0litwOwzc\n61reBrQC/Z1933XW/5LOyuZ9wHBgLzAC6LKKyx0IvNTWwtq1vncvusWL4R/+AWbPDnbcgQN2bBwD\nwdq1MHIk/N3flTol4Ro4EL773eDHnX++/a3CCATptL/OZBm1tdbUVCpL9g/kxx57LPA5vAob1gKX\nYuX+vYE7gZez9qlxtgHcB6wAjmAP+Z1YhTDAHCBTgPAycI/z/h7gV4FTnkOcfxF99hl8+GHw3ADE\nqxVLtmKU2SdJmH+rAwegd2+oqfG3f5zvf4k3r0BwBivaeR1r/vki1vJnvvMCa020EWti+mWsHiDj\nAeDfsHqEq4G/d9YvBBqw5qOzneWCxfmLsGyZBYE+fYIfO2uWFSkdPx5+ugqlQHC2q66yaSNbWws/\nV5BiIYj3/S/x5qcR3mvOy+0p1/vVwOVdHLseuD7H+oPAXB/XDiTOX4RCBkmrqbEmjatWxeuhe/gw\nNDfDzTeXOiXx4Z7gZv587/27E6TpKNj9v3dvYdeUyhTTdij5yQSCOM47W+gv5zgWD61YAddfH14L\nmXIR1t9KOQIplrIKBNXVUFVlv1TjpLXViguuuir/c8QxEKhYKLe5c60oMGiLo2xBcwRDhlhd1Jkz\nhV1XKk9ZBQKI56+ixkZ7OHQ31aCXujrYti1eQwgoEOQ2YoS1pHrvvcLOEzRH0LMnDB5slcwiQSgQ\nFEEYD8xevWDmTBtiIQ7a2iwoTZ5c6pTEUxg5uKA5Aojn/S/xp0AQsfZ2KyaYG0LVeJyKh5Yssf4Q\nVVWlTkk8FTqC6fHjcPCg5SyCiNv9L8mgQBCxtWttGOELLyz8XJlAEIfKcBULde/mm2HdOjhyJL/j\nW1ttDoKggTZu978kgwJBxMJ8YF52mdUzbN4czvny1dGhQOCluhquu85aVuUjn2IhgOHD43X/SzIo\nEEQszEnWU6l4TK6+YYMNwTB2bGnTEXeF/K2CVhRnxO3+l2RQIIjQkSNWPBBmh6s41BMoN+BPIX+r\nfHMEcbr/JTkUCCK0YoUVD4TZ4WrOHFi5srRTEioQ+DN5st2Lu3YFP1Y5AimmsgwEcelmH8UDc8gQ\nG4b57bfDPa9fJ07YcN+zZpXm+klSVWUtq5YsCX6scgRSTGUXCOJUWRbVL+dSFg+tWgUTJ/ofEbPS\n5fO36uiweZkVCKRYyi4Q9O9vzSvzbbYXll27LGcyZUr45y5lIFCxUDCZv1VHh/9jdu2CQYOgX7/g\n1xs6FD79tPDhLaSylF0gSKXi8auosTG6DlfTp8OmTTbBerEpEAQzdqxNVrNxo/9j8i0WAuuBXlNj\nwUDEr7ILBBCfQBDVA7NvX7jxRli+PJrzd+XAAavE9DuHrpigObh8K4oz4nD/S7IoEESgo8MqCKP8\n5VyK/gRLl0J9fXHmJi4nQf9WheQIoPT3vySPAkEENm604oBx46K7RqFj2eRj8WIVC+Vj1ixraXXi\nhL/9lSOQYlMgiEAxytEnTrQK8W3bor1ORjqt+oF81dTYXBRvvulvf+UIpNgUCCJQjAdmKmUjmhar\neGjLFrvmZZcV53rlJkg9gXIEUmwKBCE7cQLeeqs4Ha6K2Yw0E9wKmVynkvn9Wx06ZPfQsGH5X0uB\nQIJSIAjZm29aMcDAgdFfK6wpEf1QsVBhbrgBtm71nj0sUyxUSMBVIJCgFAhCVswH5siR1pN63bpo\nr3P6tI2bNGdOtNcpZ35nmCu0WAgUCCQ4BYKQFbtlTTGKh9assYfT0KHRXqfc+flbFVpRDAoEElxZ\nBoKaGjh1yqb7K6ZMh6upU4t3zWL0JwhzToVKlvlbdTfDXBg5gmHDbD7pIMNaSGUry0CQStmXodi/\nipYutex/MTtczZxp02EePRrdNVQ/EI5Mi6uPP+56nzByBH362JhbBw8Wdh6pHGUZCKA02eNSPDCr\nq+Haa/OfEtHL559bB7np06M5fyVJpbyLh8LIEYCKhyQYBYKQlLLDVZT1BMuX27hGfftGc/5K093f\n6vRpG3l0zJjCr6NAIEEoEITk448tGFx+efGumRFlIFCxULjmzLHcW64Z5n77WxgxAnr3Lvw6CgQS\nhJ9AcAuwGfgEeDjH9kHAS8B6YA1wpWvbdmAD0Ay841q/AGhz1jc71whVsb8Ipexwde21sHu3vcKm\nQBCuoUOtDmDNmnO3tbQUXj+QoUAgQXgFgipgEfagngDcBYzP2udRYB0wCbgbeNK1LQ3UA5OBuqz1\nP3LWTwZ+k1fqu1GqQFAKhUyJ2J3t2+GLL2xcIwlPVzm41tZw6gdAgUCC8QoEdcBW7Jf9aeAF4Las\nfcYDmZHxtwBjAXeL865+I0f627mYX4RMh6u5c4tzvVyiKB5qbLT/U4+yLUAsja7+VmFVFIMCgQTj\n9RUfCex0Lbc569zWA3c47+uAMcAoZzkNLAHWAvdlHfeAc+wzQOgDMhTzi7BmjWXpS9nhat48yxF0\n10Y9KPUfiMaMGTbD3KFDZ68Po+lohgKBBNHTY7ufx8pCrDioGdjo/JsZ/WYGsBvLITRidQ1vAD8B\nvu/s8z+AHwLfzHXyBQsW/P59fX099fX1PpJU3C9CHMrRx42zpqSbNoVTlNPebuMYPfFE4eeSs/Xt\nC9OmWYus22/vXB9mjmD4cAWCStHU1ERTU1NB5/AqnpmKVexmKnP/FugAHu/mmG3ARCB7+vjvOet+\nmLV+LPCKc0y2dDrPn7iffgqXXAKffZbX4YHceCN8//ulLRoC+Pa34dJL4TvfKfxca9fCPffABx8U\nfi451z/+o80l8eMf23I6bT3id+ywiesLtWOH5Tx27vTeV8pLylqsBCp69yoaWgtcij2sewN3Ai9n\n7VPjbAMr/lmBPfD7AQOc9dXAPCzHADDCdfzXXOtDM2iQ9bY9eTLsM5/t0CHrcDVjRrTX8SPMeoI4\n5HLKWfbf6ne/g549wwkCYDni/fvDLSqU8uUVCM4A9wOvAx8CLwIfAfOdF1hroo1Ysc+XgQed9bVY\nMdD7WLPSXwOZyRUfx5qVrgdmAg8V/l85W48eVma/f3/YZz7b8uWWzY9Dh6vZs2HVKv9TInZH01JG\na+JE+xGxfbsth9l0FOx+7NvXeoaLePGqIwB4zXm5PeV6vxrI1Y1qG3BNF+e828d1C5apJxg9Orpr\nxOmX88CBcOWVNjHO7Nn5n+foUSsamjkzvLTJ2Xr06Jxh7r77wm06mpG5/8PKZUj5KuuGgcWoMI5T\nIIBwiodWroQpU2zgMomO+28Vdo4A1HJI/FMgKMD27Za9v/rq6K4RVBiBIG7BrVw1NNiIte3t0eYI\nRLyUfSDYuze688exw9XUqfDJJ9ZqKl/qP1AcmRnmmpvDbTqaoUAgfsXoERa+qNtSx/GXc+/ecPPN\n3lMidmXPHhuz6Nprw02X5JbJwYXZmSxDgUD8KutAEOUXob3dHrZxCwRQWPHQkiUwa5aNXyTRa2iA\nV16x5qOjRnnvH4QCgfilQJCn5mY7/8jsATdiIBMI8mlDHsdcTjnLzDB30UXhB18FAvFLgSBPcX5g\nXnEFnDkDW7cGOy6dthxBXP9f5ah/f+uHEnb9ACgQiH9++hEkVpRfhOXL4f77ozl3oVIpuPVWuOGG\nYB3dOjpsmIOwy6qle3/4h9E0alAgCN8bb8CLL8KiRaVOSbhKMI1KIHmPNQT2YOvTB44dC39C+TFj\nLBjE9aF56pSVOwc1YIC9pHja2y031jPkn2VHj8KQIXb/l2LCpHL04IPw3HPWKi/sZ0pY8hlrqKxz\nBD162Bdh//5wy/JPnrRfcFH2WC5U795w4YWlToX4EVXFfHW1nfvwYTj//GiuUWkaG+258s47MH16\nqVMTnrKuI4Bossc7dlgLj7j+IhDJUPFQeNra7Eflt74V3RzhpaJAkIcoOv+IRCHqTpWVpLHRxvD6\n8pdtUMZyokCQhyg6/4hEQTmC8GRaCs6YYUPPZ88wl2QKBHlQjkCSQoEgHB0dnU2rzzvPhnJZvtz7\nuKRQIMhDFCNFikRBgSAcGzZY0+qxY205zEmg4kCBIA9RjBQpEgUFgnBkdyBVIEiYsL8I6bTqCCQ5\nFAjCkT0i76RJNvvbjh2lS1OYFAgC2rcP+vVTu2xJBgWCwp04AatX22CMGe4Z5sqBAkFAqh+QJFEg\nKNyqVTbHdE3N2evLqXio7APBkCHw2Wc2CFsYVD8gSaJAULiuBpjMzDDX0VH8NIWt7ANBz542eXc+\n4+7koqajkiQDBtiD6siRUqckuboKBKNGwdChNiR90pV9IIBwfxWpaEiSJJWKfqa+crZ/v33nb7gh\n9/aGhvLoZaxAEJCKhiRpVDyUv6VLbfKgrsYVK5d6AgWCgJQjkKRRIMif1wRU9fU2EumxY0VLUiQU\nCAI4etTGF9HwzpIkCgT5SafP7T+QbcAAmDIFVq4sXrqioEAQQGurdTHvURGfmpQLBYL8bNlidSyX\nXdb9fuVQPFQRj7QwA4HqByRpFAjykykW8prdTYEgIcL6Iqh+QJJIgSA/XvUDGdddBzt3JnveBz+B\n4BZgM/AJ8HCO7YOAl4D1wBrgSte27cAGoBl4x7V+MNAIfAwsBgYGTHcgyhFIJVMgCO70aVixAubM\n8d63Z08bfmLJkujTFRWvQFAFLMKCwQTgLmB81j6PAuuAScDdwJOubWmgHpgM1LnWP4IFgsuApc5y\nZMLMESgQSNIoEAS3Zo1914cO9bd/0ouHvAJBHbAV+2V/GngBuC1rn/FAZoqGLcBYwP3x5Sph+yrw\nvPP+eeB2vwnOx7Bh1rO4vb2w86hoSJJIgSA4v8VCGZlAkE5Hl6YoeQWCkcBO13Kbs85tPXCH874O\nGAOMcpbTwBJgLXCf65haIHNr7nOWI9Orlw0Y9emn+Z+jvd2GnB03Lrx0iRRDTQ2cOgXHj5c6Jcmx\neHGwQHDxxdCnD3zwQXRpilJPj+1+4ttCrDioGdjo/Jv57T0D2I3lEBqxuoY3clyjy+ssWLDg9+/r\n6+upr6/3kaRzZX4VDRuW1+G0tdkAduedl9/xIqWSStl9v29f5wxb0rXPP4dNm2xuYr9SKetv0NgI\nV10VXdpyaWpqoqmpqaBzeAWCXcBo1/JoLFfgdhi417W8DWh13u92/j2AVShfjwWCfcBwYC8wAtjf\nVQLcgaAQmUAwcWJ+x6uiWJIsc/8rEHhbvhxuvBH69g12XEMDPPssPPRQNOnqSvYP5MceeyzwObyK\nhtYCl2Ll/r2BO4GXs/apcbaBFf+sAI4A/YABzvpqYB6wyVl+GbjHeX8P8KvAKQ+o0HJS1Q9Ikqme\nwL+g9QMZs2fb3AUnT4afpqh5BYIzwP3A68CHwIvAR8B85wXWmmgjVuzzZeBBZ30t9uv/faxZ6a+x\npqJgxUkNWPPR2c5ypAr9IihHIElWW5vsdu7FlG8gGDwYrrjCZjNLGq+iIYDXnJfbU673q4HLcxy3\nDbimi3MeBOb6uHZowsgR3JbdXkokIZQj8Gf7dvjii/yLkDOth/KsyiyZiuhZDOHkCFQ0JEmlQOBP\nY6PNRZzveGJJ7U+gQOCTOpNJkikQ+JNvsVDGtGmweTMcPBhemopBgcCHzz6zLudDhoSbJpFiUSDw\n1t5uE9EUEgj69LFmp8uWhZeuYlAg8CFTUew1CqFIXCkQeFu3zqb1HJndZTagefOSN31lxQSCYcPg\nwAGbyDsoNR2VpFMg8FZosVBGEoebqJhA0KcPVFdbMU9QajoqSTdokE2neOJEqVMSX2EFggkTbEiP\nlpbCz1UsFRMIIP9fRcoRSNL16GEjae7vsg9/ZTt6FNautYnqC5VKWcujJLUeUiDwQTkCKQcqHura\nypU293D//uGcL2nNSBUIfFDTUSkHCgRdC6tYKGPuXBuz6MyZ8M4ZJQUCD6dOwZ49cNFF0aRJpFgU\nCLoWdiAYPhxGj7bipiRQIPCwY4c1J+vVK5o0iRSLAkFue/bArl0293CYklQ8pEDgQRXFUi6GD1cg\nyGXJEhs5tKoq3PNm5idIAgUCD6oolnKhHEFuYRcLZdx0EzQ3w+HD4Z87bAoEHpQjkHKhQHCudDq6\nQNCvH9TVQYGThxWFAoEH5QikXCgQnGvTJntgR/VjLyn1BBUXCPbvD9b1WzkCKRcKBOeKKjeQoUAQ\nQ+edB717w6FD/vZPp5UjkPJxwQU26crp06VOSXxEHQgmT7YxztqyZ3qPmYoKBBDsV9H+/TaBdU1N\ntGkSKYYePWwodQ0zYU6ehDfftBZDUenRA+bMiX+uQIGgG5qVTMqNioc6vfUWjB9vA/JFKQnFQ37m\nLC4rQb4IGlpCyk1tLfz619aBKohLLrGHZtQOHIC3347+OgAvvmht/aPW0ACPPgqvvBL82Msvh8su\nCz9N2RQIuqGKYik3f/zH8J//Ce++6/+Y48ctcHz0UXTpynjsMVi1yoZniFoqBV//evTXGTPGPvd/\n+Zfgx/7pnyoQRCJo0VAYw9KKxMW3vmWvINrbbWKntjYYNSqadGUsXmy/1CdPjvY6xfbjH5c6Bd1T\nHUE3lCMQsaEXijG+/o4d8PnnMGlStNeRc1VcIBg+HPbu9bevmo6KmGJUeDY2WsDpUXFPpdKruI/c\nb47g2DE4eBAuvDD6NInEXUODDc6Wz5zffkXdpl+6pkDQhW3bYOzY8EckFEmiMWNg4EDYsCGa83d0\nwNKlCgSlUrGBwGuYCTUdFTlblMVDzc02p3LUldGSW8UFgupq+5XvNTSsKopFztbQYK16oqBiodLy\nEwhuATYDnwAP59g+CHgJWA+sAa7M2l4FNAPu7hQLgDZnfbNzjaLxUzykimKRs82aZZ29jh8P/9wK\nBKXlFQiqgEXYg3oCcBeQ3b/wUWAdMAm4G3gya/uDwIeAuzAmDfwImOy8fpNH2vPmJxAoRyBytpoa\nmDjROnyF6dgxWLMG6uvDPa/45xUI6oCtwHbgNPACcFvWPuOB5c77LcBYYKizPAr4A+BpIJV1XPZy\n0ShHIJKfKKZfXLkSpkyBAQPCPa/45xUIRgI7Xcttzjq39cAdzvs6YAwWAACeAP4ayNXo7AHn2GeA\ngf6TXDjG93C5AAAIWUlEQVSvQNDeDtu3w7hxRUuSSCJEUWGsYqHS8woEfqZwWYg9yJuB+51/O4Cv\nAPud5exf/z8BxgHXAHuAH/pPcuG8AsHu3TB4sM1cJCKd6uqsaXWYQ1krEJSe11hDuwD38E+jsVyB\n22HgXtfyNqAVuBP4KlY01Bc4H/hXrB7BfRs9zdkVyWdZsGDB79/X19dTH0JBYm1t9+2hVT8gkluv\nXjb+1tKlcNddhZ9v717YuROuu67wc1WqpqYmmgqcGNmrnL4nVu4/B9gNvINVGLvHIawBjgOngPuA\n6cCfZZ1nJvDfgD9ylkdgOQGAh4DrgT/Jcf10Osi8kj798pfws5/BSy/l3v7ss7BiBTz/fOiXFkm8\nRYtg3Tr7nhTqZz+D//gPe0k4UqkUBKyD9coRnMGKe17HWhA9gwWB+c72p7DWRD/FipE2Ad/s4lzu\nJ/rjWLFQGstBzM95RES8iobUmUykaw0NsHChdcpMFdjkQ8VC8VCyljs+RZIj+OQTuOUWe+Dn8vWv\nw1e+YmOBi8jZ0mkbcuL11wubrCadhpEjrdXQJZeEl75Kl0+OoOJ6FoN3jkBNR0W6lkqF03roww+h\nTx991+KgIgPBgAHWRPTo0dzbVVks0r0w+hM0Ntp5Ci1eksJVZCBIpbrOFXz+OZw8aTMyiUhuc+ZY\nkc7p0/mfY/Fi1Q/ERUUGAug6ELS2Wm5Av1JEujZkiJXr5zvR/MmTNlTF7Nnhpkvyo0CQRfUDIv4U\nUk+wejVccYV13JTSUyDIovoBEX8KCQRqNhovCgRZlCMQ8Wf6dNi0yerVglIgiBcFgizqTCbiT9++\ncOONsGxZsOMOHoTNm2HatGjSJcEpEGRR0ZCIf/kUDy1bBjNmWB8CiQcFApfTp23k0TFjSpMmkaTJ\npz9Bpv+AxIcCgcuOHTBiBPTuXZo0iSTNxIlw5IgNTe1HOq3+A3GkQOCiimKRYFIpmDvXf66gpQVO\nnYIJE6JNlwRTsYFg4EA4ccJeGaofEAkuSD1BY6MFDnXYjJeKDQSplA0j4c4VKEcgEtzcuVYB3N7u\nva+ajcZTxQYCOLd4SDkCkeBGjoThw22ymu6cOQPLl1vgkHip6EAwfLhyBCJhaGiwSuDurF0Lo0fb\n907ipaIDQW2tzZkK1ppBnclE8uOnnkDFQvFV8YEgkyM4cMAm5h44sLRpEkmimTPtF/+RI13vo/4D\n8aVA4AQCFQuJ5K9/f7juOpujIJfDh6G5GW66qbjpEn8UCJxAoIpikcJ0Vzy0YgXU1UG/fsVNk/ij\nQKAcgUgougsEqh+INwUC5QhEQnHttTZW1+7d527TsBLxpkCgHIFIKKqqbOrJJUvOXt/WZo0xJk8u\nTbrEW0UHgkGD4OhRmz9VTUdFCperP0Fjo01236OinzbxVtF/mh49YOhQ+O1v4dNPrYekiOSvocFy\nBOl05zrVD8RfRQcCsOKht9+2OQiqqkqdGpFk+9KXoLoaNm605Y4OCwwKBPGmQFALb72limKRsLgn\nq9mwwYpgNdlTvCkQOIFA9QMi4XA3I1WxUDL4CQS3AJuBT4CHc2wfBLwErAfWAFdmba8CmoFXXOsG\nA43Ax8BioGQDO9TWwqZNyhGIhGX2bHjzTZvrQ4EgGbwCQRWwCAsGE4C7gPFZ+zwKrAMmAXcDT2Zt\nfxD4EHBVH/EIFgguA5Y6yyVRW2vlmHHPETQ1NZU6CbGgz6FTXD+LgQPhyittjoLVq6G+PvprxvWz\nSAqvQFAHbAW2A6eBF4DbsvYZDyx33m8BxgJDneVRwB8ATwPuOYm+CjzvvH8euD1wykNSW2v/xj1H\noBvd6HPoFOfPoqEBFiyAq6+GmprorxfnzyIJvALBSGCna7nNWee2HrjDeV8HjMECAMATwF8DHVnH\n1AKZmQD2OcslkZRAIJIkDQ3w7rsqFkoKr0CQ9tgOsBAr428G7nf+7QC+Aux3lruboTTt8zqRGDHC\nXtXVpUqBSPmZOtVGJFUgKA9Tgd+4lv+W3BXGbtuAAcDfY7mJbcAe4Cjwr84+m4HMPEUjnOVcttIZ\nKPTSSy+99PJ+bSVkPYEWrNy/N/A+51YW1zjbAO4DfprjPDM5u9XQD+gMKI9guQoREYmpW7FK4K1Y\njgBgvvMCmOZs3wz8AgsM2WYCL7uWBwNLiEHzURERERERiSGvTmyVZDuwAat0f6e0SSm6Z7FWZRtd\n62LTGbHIcn0WC7CWfM3O65biJ6skRmNN1j8ANgF/6ayvxHujq89iAQm/N6qwYqixQC9y10tUkm3Y\nDV6JbgImc/bD7wfA3zjvH6Zy6pdyfRbfA75TmuSU1HDgGud9f6xoejyVeW909VkEujfiONaQn05s\nlaa75rfl7A3gs6x1semMWGS5PguozHtjL/YDEeAI8BHWv6kS742uPgsIcG/EMRD46cRWSdJYxfpa\nrFVWpYtNZ8SYeADr1PkMlVEUkm0sllNag+6Nsdhn8baz7PveiGMgSJc6ATEzHfvj3gr8V6yIQEym\n3XSl+gkwDisa2AP8sLTJKbr+wC+x8cwOZ22rtHujP9Zq80EsZxDo3ohjINiFVYBkjMZyBZVqj/Pv\nAWyU17oSpiUO9nF2Z8T9JUxLqe2n84H3NJV1b/TCgsD/AX7lrKvUeyPzWfyMzs8i0L0Rx0CwFriU\nzk5sd3J2H4RK0g/rpQ1QDczj7MrCSvQycI/z/h46b/xKNML1/mtUzr2Rwoo7PgT+ybW+Eu+Nrj6L\nsrg3cnViq0TjsIqg97GmYZX2Wfw7sBs4hdUbfYPK7YyY/Vnciw3ZsgErB/4VlVMmPgMbz+x9zm4e\nWYn3Rq7P4lYq994QEREREREREREREREREREREREREREREREREZHu/H8LssqB+qvqYgAAAABJRU5E\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108d31f50>"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first graph shows me that after 40, the accuracy decreased steadily.\n",
      "The second graph allows me to see that the value 15 give me the same accuracy as 11. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question 5**. OPTIONAL BONUS QUESTION: Using the value of K obtained in (3) above, vary the number of folds used for cross-validation across an interesting range, e.g. [ 2, 3, 5, 6, 10, 15]. How does classifier accuracy vary with the number of folds used? Do you think there exists an optimal number of folds to use for this particular problem? Why or why not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vary_fold(num_fold):\n",
      "    return cross_validate(X,y,KNeighborsClassifier(11).fit, num_fold)\n",
      "\n",
      "vary_fold(5)\n",
      "vary_fold(2)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "0.95333333333333337"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "folds = [2,3,4,5,6,10,15]\n",
      "for num_fold in folds:\n",
      "    results.append(vary_fold(num_fold))\n",
      "    \n",
      "results    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "[0.95333333333333337,\n",
        " 0.96666666666666667,\n",
        " 0.96692745376955913,\n",
        " 0.96666666666666656,\n",
        " 0.96666666666666667,\n",
        " 0.95999999999999996,\n",
        " 0.96666666666666667]"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that in the values given, the optimal number of folds is for 4 folds because it gives the best accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    }
   ],
   "metadata": {}
  }
 ]
}